# -*- coding: utf-8 -*-
"""densenet121.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b1npEWxZESHbrV3jkPBit0tKt3Bu6khC

# imports
"""

from __future__ import print_function
from __future__ import division
import numpy as np
import os
import random
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.metrics import confusion_matrix
import PIL.Image
import matplotlib.cm as cm
from IPython.display import Image, display
from collections import OrderedDict
import cv2
import itertools
import matplotlib.image

import torch
import torchvision
x = torch.rand(5, 3)
#print(x)
#print(torch.cuda.is_available())
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
import time
import copy
#print("PyTorch Version: ",torch.__version__)
#print("Torchvision Version: ",torchvision.__version__)
from torchvision.models import *
from collections import OrderedDict

# Random seed for reproducibility
seed = 42
random.seed(seed)
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
torch.manual_seed(seed)

"""# dataset handling"""

labels=['COVID-19','Non-COVID','normal']

train_data_path='/data/data1/users/el17074/my_data/Lung Segmentation Data/Masked_Train'
valid_data_path='/data/data1/users/el17074/my_data/Lung Segmentation Data/Val'
test_data_path='/data/data1/users/el17074/my_data/Lung Segmentation Data/Test'

"""# normalization"""

norm_transforms = transforms.Compose([transforms.Resize(255),
                                      transforms.CenterCrop(224),
                                      transforms.ToTensor(),
                                      #transforms.Normalize([0.5, 0.5, 0.5],[0.224, 0.224, 0.224]),
                                       ])


"""# data loading"""

my_transforms = norm_transforms
image_datasets = {x: datasets.ImageFolder('/data/data1/users/el17074/my_data/Lung Segmentation Data/'+x, transform=my_transforms) for x in ['Masked_Train','Test', 'Val','Small_Test']}
dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['Masked_Train', 'Val']}
testdata_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['Test']}
Small_testdata_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['Small_Test']}

"""# helper functions"""

def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25, is_inception=False):
    #since = time.time()

    val_acc_history = []

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['Masked_Train', 'Val']:
            if phase == 'Masked_Train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'Masked_Train'):
                    # Get model outputs and calculate loss
                    # Special case for inception because in training it has an auxiliary output. In train
                    #   mode we calculate the loss by summing the final output and the auxiliary output
                    #   but in testing we only consider the final output.
                    if is_inception and phase == 'Masked_Train':
                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958
                        outputs, aux_outputs = model(inputs)
                        loss1 = criterion(outputs, labels)
                        loss2 = criterion(aux_outputs, labels)
                        loss = loss1 + 0.4*loss2
                    else:
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)

                    _, preds = torch.max(outputs, 1)

                    # backward + optimize only if in training phase
                    if phase == 'Masked_Train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
                
            scheduler.step()

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

            # deep copy the model
            if phase == 'Val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
            if phase == 'Val':
                val_acc_history.append(epoch_acc)

        print()

    #time_elapsed = time.time() - since
    #print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model, val_acc_history,best_acc

def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)



"""# build model without class(comment all if gridsearch)"""


fcmiddlenumber=256
numberoftraininglayers=3
model= models.vgg19(weights=VGG19_Weights.DEFAULT)
num_ftrs = model.classifier[0].in_features
set_parameter_requires_grad(model, True)
if numberoftraininglayers==1:
  for param in model.features[28:].parameters():
    param.requires_grad = True
elif numberoftraininglayers==2:
  for param in model.features[19:].parameters():
    param.requires_grad = True
elif numberoftraininglayers==3:
  for param in model.features[10:].parameters():
    param.requires_grad = True


#allakse edo .classifier gia densenet, .fc gia resnet
model.classifier=  nn.Sequential(OrderedDict([('fc1', nn.Linear(num_ftrs, fcmiddlenumber)),('relu', nn.ReLU()),('dropout',nn.Dropout()),('fc2', nn.Linear(fcmiddlenumber, 3))]))
model = model.to(device)


"""# training(comment all if gridsearch)"""


path='/data/data1/users/el17074/mymodels/vgg/vgg19masked/'

optimizer= optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
criterion = nn.CrossEntropyLoss()
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
# Train and evaluate
start_time = time.time()
model1, hist,best_acc = train_model(model, dataloaders_dict, criterion, optimizer,scheduler, num_epochs=8, is_inception=False)
print("--- %s seconds ---" % (time.time() - start_time))
torch.save(model1.state_dict(),path+'weights.pt')

"""# grid search(comment all if not gridsearch)"""
'''
path='/data/data1/users/el17074/mymodels/vgg/vgg19gridsearched/'

def grid_search(dataloaders_dict, num_epochs):
    # Define the parameter grid
    param_grid = {'lr': [0.001,0.01],
                  'momentum': [0.9],
                  'step_size': [5,7],
                  'gamma': [0.1],
                  'numberoftraininglayers':[0,1,2,3],
                  'fcmiddlenumber': [1024,256]
                  }

    
    
    # Get all possible combinations of the parameter grid
    param_combinations = list(itertools.product(*(param_grid[param] for param in param_grid)))
    print(len(param_combinations))
    start_time = time.time()
    best_acc = 0
    best_params = {}
    best_model = None
    # Iterate over all parameter combinations
    for lr, momentum, step_size, gamma ,numberoftraininglayers,fcmiddlenumber in param_combinations:
        model= models.vgg19(weights=VGG19_Weights.DEFAULT)
        set_parameter_requires_grad(model, True)
        num_ftrs =  model.classifier[0].in_features
        print(lr, momentum, step_size, gamma ,numberoftraininglayers,fcmiddlenumber)
        #model training depth
        if numberoftraininglayers == 1:
            for param in model.features[28:].parameters():
                param.requires_grad = True
        elif numberoftraininglayers == 2:
            for param in model.features[19:].parameters():
                param.requires_grad = True
        elif numberoftraininglayers == 3:
            for param in model.features[10:].parameters():
                param.requires_grad = True
 
        #model fc
        model.classifier =  nn.Sequential(OrderedDict([('fc1', nn.Linear(num_ftrs, fcmiddlenumber)),('relu', nn.ReLU()),('dropout',nn.Dropout()),('fc2', nn.Linear(fcmiddlenumber, 4))]))
        model = model.to(device)
        # Define the optimizer
        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)
        # Define the criterion
        criterion = nn.CrossEntropyLoss()
        # Define the scheduler
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
        # Train and evaluate the model
        if numberoftraininglayers==2 or numberoftraininglayers==3 :
          model_temp, hist ,train_best_acc= train_model(model, dataloaders_dict, criterion, optimizer, scheduler, num_epochs+5, is_inception=False)
        else:
          model_temp, hist ,train_best_acc= train_model(model, dataloaders_dict, criterion, optimizer, scheduler, num_epochs, is_inception=False)
        # Get the accuracy from the history
        acc = train_best_acc
        # Update the best accuracy and best parameters if necessary
        if acc > best_acc:
            best_acc = acc
            best_params = {'lr': lr, 'momentum': momentum, 'step_size': step_size, 'gamma': gamma, 'numberoftraininglayers':numberoftraininglayers, 'fcmiddlenumber':fcmiddlenumber }
            best_model = model_temp
            best_model_hist = hist
        print("--- %s seconds ---" % (time.time() - start_time))
    return best_model, best_params, best_acc, best_model_hist



start_time = time.time()
model0,model0_params,model0_acc,model0_hist=grid_search(dataloaders_dict, 10)
torch.save(model0.state_dict(),path+'weights.pt')
print(model0_params)
print(model0_acc)
print(model0_hist)
print("--- %s seconds ---" % (time.time() - start_time))
'''
"""# model selection(change here depending on grid search or not)"""

fcmiddlenumber=256#model0_params['fcmiddlenumber']#500
model1= models.vgg19()
num_ftrs = model1.classifier[0].in_features
model1.classifier=  nn.Sequential(OrderedDict([('fc1', nn.Linear(num_ftrs, fcmiddlenumber)),('relu', nn.ReLU()),('dropout',nn.Dropout()),('fc2', nn.Linear(fcmiddlenumber, 4))]))
model1.load_state_dict(torch.load(path+'weights.pt'))
model1=model1.to(device)
model1.eval()

"""# predictions (change here depending on grid search or not)"""

#kanei gia 5 batch
count=0
allclasses=torch.Tensor()
allinputs=torch.Tensor()
for inputs, classes in testdata_dict['Test']:
  allclasses= torch.cat((allclasses, classes), 0)
  allinputs= torch.cat((allinputs, inputs), 0)
  count=count+1
  if count==5:
    break
model1 = model1.to(device)
allinputs=allinputs.to(device)
with torch.no_grad(): 
  outputs=model1(allinputs)
  _, preds = torch.max(outputs, 1)
  preds=preds.cpu().numpy()
  classes=allclasses.numpy()

#importing confusion matrix
from sklearn.metrics import confusion_matrix
confusion = confusion_matrix(classes, preds)
print('Confusion Matrix\n')
print(confusion)

#importing accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
print('\nAccuracy: {:.2f}\n'.format(accuracy_score(classes, preds)))

print('Micro Precision: {:.2f}'.format(precision_score(classes, preds, average='micro')))
print('Micro Recall: {:.2f}'.format(recall_score(classes, preds, average='micro')))
print('Micro F1-score: {:.2f}\n'.format(f1_score(classes, preds, average='micro')))

print('Macro Precision: {:.2f}'.format(precision_score(classes, preds, average='macro')))
print('Macro Recall: {:.2f}'.format(recall_score(classes, preds, average='macro')))
print('Macro F1-score: {:.2f}\n'.format(f1_score(classes, preds, average='macro')))

print('Weighted Precision: {:.2f}'.format(precision_score(classes, preds, average='weighted')))
print('Weighted Recall: {:.2f}'.format(recall_score(classes, preds, average='weighted')))
print('Weighted F1-score: {:.2f}'.format(f1_score(classes, preds, average='weighted')))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(classes, preds, target_names=['COVID-19','Non-COVID','normal']))

f = open(path+'readme.txt', "w")

f.write('vgg19')
f.write('0.01,0.9,7,0.1,2,256')
f.write('numberoftraininglayers= 2')
f.write('fcmiddlenumber= 256')

#f.write(str(model0_params['lr']))
#f.write(str(model0_params['momentum']))
#f.write(str(model0_params['step_size']))
#f.write(str(model0_params['gamma']))
#f.write(str(model0_params['numberoftraininglayers']))
#f.write(str(model0_params['fcmiddlenumber']))
#f.write("--- %s seconds ---" % (time.time() - start_time))

f.write('\nAccuracy: {:.2f}\n'.format(accuracy_score(classes, preds)))

f.write('Micro Precision: {:.2f}'.format(precision_score(classes, preds, average='micro')))
f.write('Micro Recall: {:.2f}'.format(recall_score(classes, preds, average='micro')))
f.write('Micro F1-score: {:.2f}\n'.format(f1_score(classes, preds, average='micro')))

f.write('Macro Precision: {:.2f}'.format(precision_score(classes, preds, average='macro')))
f.write('Macro Recall: {:.2f}'.format(recall_score(classes, preds, average='macro')))
f.write('Macro F1-score: {:.2f}\n'.format(f1_score(classes, preds, average='macro')))

f.write('Weighted Precision: {:.2f}'.format(precision_score(classes, preds, average='weighted')))
f.write('Weighted Recall: {:.2f}'.format(recall_score(classes, preds, average='weighted')))
f.write('Weighted F1-score: {:.2f}'.format(f1_score(classes, preds, average='weighted')))


f.close()

"""# GradCAM"""

from pytorch_grad_cam import GuidedBackpropReLUModel
from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget,RawScoresOutputTarget #an to kaleso me ari8mo eksigi gia tin katigoria ayti
from pytorch_grad_cam.utils.image import show_cam_on_image ,deprocess_image,preprocess_image

#model1.layer4

#model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
#model.fc = nn.Linear(2048, 4)
#target_layers = [model1.base_model.layer4[-1]]

model = model1
target_layers = [model.features[-1]]#[model.layer4[-1]]
cam = GradCAM(model=model, target_layers=target_layers,use_cuda=True)#True

#1 batch prediction
inputs, classes = next(iter(testdata_dict['Small_Test']))
rawinputs=inputs
model1 = model1.to(device)
inputs=inputs.to(device)
with torch.no_grad(): 
  outputs=model1(inputs)
  _, preds = torch.max(outputs, 1)
  preds=preds.cpu().numpy()
  classes=classes.numpy()
#print(preds)
#print(classes)
#plt.imshow(rawinputs[0].permute(1,2,0))
#plt.show()

x=ClassifierOutputTarget(31)
x(preds)

im = transforms.ToPILImage()(inputs[0]).convert('RGB')
im = np.asarray(im, dtype="float32" )/255
input_tensor = inputs
targets = None #xrisimopoiei ta preds oysiastika
grayscale_cam= cam(input_tensor=input_tensor, targets=targets,aug_smooth=True,eigen_smooth=True)

visualization = show_cam_on_image(im, grayscale_cam[0], use_rgb=True)
visualization = transforms.ToPILImage()(visualization)
#display(visualization)

input_img = preprocess_image(im)
gb_model = GuidedBackpropReLUModel(model=model, use_cuda=True)#True
gb = gb_model(input_img, target_category=None)

cam_mask = cv2.merge([grayscale_cam[0], grayscale_cam[0], grayscale_cam[0]])
cam_gb = deprocess_image(cam_mask*gb)
gb = deprocess_image(gb)
gb = transforms.ToPILImage()(gb)
#display(gb)
cam_gb = transforms.ToPILImage()(cam_gb)
#display(cam_gb)

fig, ax = plt.subplots(1,4, figsize=(25, 25))
ax[0].imshow(rawinputs[0].permute(1,2,0))
ax[0].set_title('Original Image')
ax[1].imshow(visualization)
ax[1].set_title('GradCAM')
ax[2].imshow(gb)
ax[2].set_title('GuidedBackprop')
ax[3].imshow(cam_gb)
ax[3].set_title('GradCAM+GuidedBackprop')
plt.savefig(path+'gradcam0.png')

#kathe eikona me th problepsi kai to gradcam poy thn aitiologei
fig, ax = plt.subplots(8,4, figsize=(15, 15))
x,y=0,-1
for i in range(0,32):
  im = transforms.ToPILImage()(inputs[i]).convert('RGB')
  im = np.asarray(im, dtype="float32" )/255
  visualization = show_cam_on_image(im, grayscale_cam[i], use_rgb=True)
  visualization = transforms.ToPILImage()(visualization)
  
  if i%4==0:
    x=0
    y+=1
  ax[y,x].imshow(visualization)
  ax[y,x].set_title('class '+ str(preds[i]))
  x+=1
plt.savefig(path+'gradcam1.png')

#mporo na kano targets=ClassifierOutputTarget(0) gia na deikso ti 8a me ekane na po oti einai tis klasis 0
#mporo na kano targets=ClassifierOutputTarget(1) gia na deikso ti 8a me ekane na po oti einai tis klasis 1 krlp
#na do ta metrix poy leei

"""# lime"""

#https://towardsdatascience.com/how-to-explain-image-classifiers-using-lime-e364097335b4

from lime import lime_image

#1 batch prediction
inputs, classes = next(iter(testdata_dict['Test']))
rawinputs=inputs
model1 = model1.to(device)
inputs=inputs.to(device)
with torch.no_grad(): 
  outputs=model1(inputs)
  _, preds = torch.max(outputs, 1)
  preds=preds.cpu().numpy()
  classes=classes.numpy()
#print(preds)
#print(classes)
#plt.imshow(rawinputs[0].permute(1,2,0))
#plt.show()

def get_preprocess_transform():   
    transf = transforms.Compose([
        transforms.ToTensor()
    ])    

    return transf    
preprocess_transform = get_preprocess_transform()


def batch_predict(images):
    model2=model1
    model2.eval()
    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model2 = model2.type(torch.cuda.FloatTensor).to(device)
    batch = batch.type(torch.cuda.FloatTensor).to(device)
    


    logits = model2(batch)
    probs = F.softmax(logits, dim=1)
    return probs.detach().cpu().numpy()

test_pred = batch_predict([np.array(inputs[0].permute(1,2,0).cpu())])
test_pred.squeeze().argmax()

image=np.array(inputs[0].permute(1,2,0).cpu()).astype('double')
#image=image.to(device)
explainer = lime_image.LimeImageExplainer()
explanation = explainer.explain_instance(image,
                                         batch_predict,
                                         top_labels=3, 
                                         hide_color=None, #None
                                         num_samples=1000) # number of images that will be sent to classification function

from skimage.segmentation import mark_boundaries
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
img_boundry1 = mark_boundaries(temp, mask)
plt.imshow(img_boundry1)
matplotlib.image.imsave(path+'lime0.png', img_boundry1)

fig, ax = plt.subplots(1,3, figsize=(25, 25))
for i in range(0,3):
  temp, mask = explanation.get_image_and_mask(explanation.top_labels[i], positive_only=True, num_features=5, hide_rest=False)
  img_boundry = mark_boundaries(temp, mask)
  ax[i].imshow(img_boundry)
  x=i
  ax[i].set_title('Areas that contribute to prediction for class ' +str(i))
  #edo moy deixnei ta top positive
  plt.savefig(path+'lime1.png')

fig, ax = plt.subplots(1,3, figsize=(25, 25))
for i in range(0,3):
  temp, mask = explanation.get_image_and_mask(explanation.top_labels[i], positive_only=False, num_features=5, hide_rest=False)
  img_boundry = mark_boundaries(temp, mask)
  ax[i].imshow(img_boundry)
  x=i
  ax[i].set_title('Areas that contribute to prediction for class ' +str(i))
#edo moy deixnei ta top genika, na paratiriso diafores
plt.savefig(path+'lime2.png')

fig, ax = plt.subplots(1,3, figsize=(25, 25))
for i in range(0,3):
  temp, mask = explanation.get_image_and_mask(explanation.top_labels[i], positive_only=False, num_features=10, hide_rest=True)
  img_boundry = mark_boundaries(temp, mask)
  ax[i].imshow(img_boundry)
  x=i
  ax[i].set_title('Areas that contribute to prediction for class ' +str(i))
#edo moy deixnei ta top genika
plt.savefig(path+'lime3.png')

#na tsekaro ayto
'''
def explanation_heatmap(exp, exp_class):
    dict_heatmap = dict(exp.local_exp[exp_class])
    heatmap = np.vectorize(dict_heatmap.get)(exp.segments) 
    plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
    plt.colorbar()
    plt.show()

explanation_heatmap(exp, exp.top_labels[0])
'''
#episis den ksero ta top labels an einai oi 3 poy 8elo h genika ta top giati dexetai kai ton ari8mo 4 poy den yparxei. ara na to do

"""# shapley"""

import shap

#1 batch prediction
inputs, classes = next(iter(testdata_dict['Test']))
rawinputs=inputs
model1 = model1.to(device)
inputs=inputs.to(device)
with torch.no_grad(): 
  outputs=model1(inputs)
  _, preds = torch.max(outputs, 1)
  preds=preds.cpu().numpy()
  classes=classes.numpy()
#print(preds)
#print(classes)
#plt.imshow(rawinputs[0].permute(1,2,0))
#plt.show()

def nhwc_to_nchw(x: torch.Tensor) -> torch.Tensor:
    if x.dim() == 4:
        x = x if x.shape[1] == 3 else x.permute(0, 3, 1, 2)
    elif x.dim() == 3:
        x = x if x.shape[0] == 3 else x.permute(2, 0, 1)
    return x

def nchw_to_nhwc(x: torch.Tensor) -> torch.Tensor:
    if x.dim() == 4:
        x = x if x.shape[3] == 3 else x.permute(0, 2, 3, 1)
    elif x.dim() == 3:
        x = x if x.shape[2] == 3 else x.permute(1, 2, 0)
    return x


transform= [
    torchvision.transforms.Lambda(nhwc_to_nchw),
    torchvision.transforms.Lambda(nchw_to_nhwc),
]

inv_transform= [
    torchvision.transforms.Lambda(nhwc_to_nchw),
    torchvision.transforms.Lambda(nchw_to_nhwc),
]

transform = torchvision.transforms.Compose(transform)
inv_transform = torchvision.transforms.Compose(inv_transform)

def predict(img: np.ndarray) -> torch.Tensor:
    model2=model1
    model2.eval()
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    img = nhwc_to_nchw(torch.Tensor(img))
    img = img.to(device)
    model2=model2.to(device)
    with torch.no_grad(): 
      output = model2(img)
    return output
# Check that transformations work correctly
class_names=['COVID-19','Non-COVID','normal']
Xtr = transform(inputs)
out = predict(Xtr[0:10])
newclasses = torch.argmax(out, axis=1).cpu().numpy()
print(f'Classes: {newclasses}: {np.array(class_names)[newclasses]}')

topk = 3
batch_size = 32
n_evals = 1000


masker_blur = shap.maskers.Image("blur(128,128)", Xtr[0].shape)
explainer = shap.Explainer(predict, masker_blur, output_names=class_names)


shap_values = explainer(Xtr[0:10], max_evals=n_evals, batch_size=batch_size,
                        outputs=shap.Explanation.argsort.flip[:topk])

shap_values.data = inv_transform(shap_values.data).cpu().numpy()
shap_values.values = [val for val in np.moveaxis(shap_values.values,-1, 0)]

shap.image_plot(shap_values=shap_values.values,
                pixel_values=shap_values.data,
                labels=shap_values.output_names,
                width=30,aspect=0.4, hspace=0.3,
                )
plt.savefig(path+'shapley0.png')

#mporo na kano gia intermeidiate layer opos to gradcam, me gradient explainer https://shap.readthedocs.io/en/latest/example_notebooks/image_examples/image_classification/Explain%20an%20Intermediate%20Layer%20of%20VGG16%20on%20ImageNet%20%28PyTorch%29.html
#kai genika na tsekaro ki alloys explainers
