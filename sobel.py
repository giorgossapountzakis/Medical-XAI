# -*- coding: utf-8 -*-
"""extras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B1fwzUO_fIchEZxs0LQUVrvQ36NFJYok

# imports
"""

from __future__ import print_function
from __future__ import division
import numpy as np
import os
import random
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.metrics import confusion_matrix
import PIL.Image
import matplotlib.cm as cm
from IPython.display import Image, display
from collections import OrderedDict
import cv2
import itertools
import matplotlib.image
from skimage.segmentation import slic
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
import time
import copy
from torchvision.models import *
from collections import OrderedDict
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Random seed for reproducibility
seed = 42
random.seed(seed)
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
torch.manual_seed(seed)

labels=['COVID-19','Non-COVID','Normal']

"""# normalization"""

norm_transforms = transforms.Compose([transforms.Resize(299),
                                      transforms.CenterCrop(299),
                                      transforms.ToTensor(),
                                      #transforms.Normalize([0.5, 0.5, 0.5],[0.224, 0.224, 0.224]),
                                       ])

"""# data loading"""

my_transforms = norm_transforms
image_datasets = {x: datasets.ImageFolder('/data/data1/users/el17074/my_data/Lung Segmentation Data/'+x, transform=my_transforms) for x in ['Masked_Train','Masked_Test', 'Masked_Val','Masked_Small_Test']}
dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['Masked_Train', 'Masked_Val']}
testdata_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['Masked_Test']}
Small_testdata_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=False) for x in ['Masked_Small_Test']}
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

"""# model selection(change here for fcmiddlenumber and .fc)"""


path='/data/data1/users/el17074/mymodels/inception/inceptionv3masked/'
fcmiddlenumber=256		
model1= models.inception_v3(weights=Inception_V3_Weights.DEFAULT)
aux_num_ftrs = model1.AuxLogits.fc.in_features
model1.AuxLogits.fc = nn.Linear(aux_num_ftrs, 3)
num_ftrs = model1.fc.in_features
model1.fc =  nn.Sequential(OrderedDict([('fc1', nn.Linear(num_ftrs, fcmiddlenumber)),('relu', nn.ReLU()),('dropout',nn.Dropout()),('fc2', nn.Linear(fcmiddlenumber, 3))]))
model1.load_state_dict(torch.load(path+'weights.pt'))
model1=model1.to(device)
model1.eval()



"""# predictions (change here depending on parameters)"""
print(path)
#1 batch prediction
inputs, classes = next(iter(Small_testdata_dict['Masked_Small_Test']))
rawinputs=inputs
model1 = model1.to(device)
inputs=inputs.to(device)
with torch.no_grad(): 
  outputs=model1(inputs)
  _, preds = torch.max(outputs, 1)
  preds=preds.cpu().numpy()
  classes=classes.numpy()

print(preds)
print(classes)

foundcov=False
foundnoncov=False
foundnormal=False
covposition,noncovposition,normalposition=None,None,None
i=0
for item in classes:
  if foundcov==False or foundnoncov==False or foundnormal==False:
    if classes[i]==0 and foundcov==False:
      covposition=i
      foundcov=True
    elif classes[i]==1 and foundnoncov==False:
      noncovposition=i
      foundnoncov=True
    elif classes[i]==2 and foundnormal==False:
      normalposition=i
      foundnormal=True
    i=i+1
print(covposition,noncovposition,normalposition)



"""# Basic GradCAM"""

from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad
from pytorch_grad_cam import GuidedBackpropReLUModel
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget,RawScoresOutputTarget #an to kaleso me ari8mo eksigi gia tin katigoria ayti
from pytorch_grad_cam.utils.image import show_cam_on_image ,deprocess_image,preprocess_image
from pytorch_grad_cam.metrics.road import *

print('Basic GradCAM')
start_time = time.time()
model = model1
#ALLAZO TO LAYER EDO -----------------------------------------------------------
target_layers = [model.Mixed_7c.branch_pool]
with GradCAM(model=model, target_layers=target_layers,use_cuda=True) as cam:
  im = transforms.ToPILImage()(inputs[covposition]).convert('RGB')
  im = np.asarray(im, dtype="float32" )/255
  input_tensor = inputs
  targets = None #xrisimopoiei ta preds oysiastika
  grayscale_cam= cam(input_tensor=input_tensor, targets=targets,aug_smooth=True,eigen_smooth=True)
  visualization0 = show_cam_on_image(im, grayscale_cam[covposition], use_rgb=True)
  visualization0 = transforms.ToPILImage()(visualization0)
  display(visualization0)




"""# GradCAM metrics"""

def visualize_score(visualization, score, name):
    visualization = cv2.putText(visualization, name, (10, 20), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, cv2.LINE_AA)
    visualization = cv2.putText(visualization, f"{score:.5f}", (10, 35), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1, cv2.LINE_AA)    
    return visualization



# Now lets see how to evaluate this explanation:
from pytorch_grad_cam.metrics.cam_mult_image import CamMultImageConfidenceChange
from pytorch_grad_cam.utils.model_targets import ClassifierOutputSoftmaxTarget
from pytorch_grad_cam.sobel_cam import sobel_cam


targets = [ClassifierOutputSoftmaxTarget(0)]
sobel_cam_grayscale=[]
for i in range(0,32):
    sobel_cam_grayscale.append(sobel_cam(np.uint8(inputs[i].permute(1,2,0).cpu().numpy() * 255)))
sobel_cam_grayscale=np.stack( sobel_cam_grayscale, axis=0 )

cam_metric = CamMultImageConfidenceChange()
scores, visualizations = cam_metric(input_tensor, sobel_cam_grayscale, targets, model, return_visualization=True)
score = scores[0]
#visualization = visualizations[0]
#visualization = deprocess_image(visualization)
visualization = show_cam_on_image(im,sobel_cam_grayscale[covposition], use_rgb=True)
visualization=transforms.ToPILImage()(visualization)
visualization = np.array(visualization)
visualization=visualize_score(visualization,score,'confidence increase:')
visualization=transforms.ToPILImage()(visualization)


thresholded_cam = sobel_cam_grayscale < np.percentile(sobel_cam_grayscale, 25)
cam_metric = CamMultImageConfidenceChange()
scores, visualizations = cam_metric(input_tensor, thresholded_cam, targets, model, return_visualization=True)
score = scores[0]
visualization1 = show_cam_on_image(im,thresholded_cam[covposition], use_rgb=True)
visualization1=transforms.ToPILImage()(visualization1)
visualization1 = np.array(visualization1)
visualization1=visualize_score(visualization1,score,'confidence increase:')
visualization1=transforms.ToPILImage()(visualization1)

thresholded_cam = sobel_cam_grayscale < np.percentile(sobel_cam_grayscale, 50)
cam_metric = CamMultImageConfidenceChange()
scores, visualizations = cam_metric(input_tensor, thresholded_cam, targets, model, return_visualization=True)
score = scores[0]
visualization2 = show_cam_on_image(im,thresholded_cam[covposition], use_rgb=True)
visualization2=transforms.ToPILImage()(visualization2)
visualization2 = np.array(visualization2)
visualization2=visualize_score(visualization2,score,'confidence increase:')
visualization2=transforms.ToPILImage()(visualization2)

thresholded_cam = sobel_cam_grayscale < np.percentile(sobel_cam_grayscale, 75)
cam_metric = CamMultImageConfidenceChange()
scores, visualizations = cam_metric(input_tensor, thresholded_cam, targets, model, return_visualization=True)
score = scores[0]
visualization3 = show_cam_on_image(im,thresholded_cam[covposition], use_rgb=True)
visualization3=transforms.ToPILImage()(visualization3)
visualization3 = np.array(visualization3)
visualization3=visualize_score(visualization3,score,'confidence increase:')
visualization3=transforms.ToPILImage()(visualization3)


thresholded_cam = sobel_cam_grayscale < np.percentile(sobel_cam_grayscale, 90)
cam_metric = CamMultImageConfidenceChange()
scores, visualizations = cam_metric(input_tensor, thresholded_cam, targets, model, return_visualization=True)
score = scores[0]
visualization4 = show_cam_on_image(im,thresholded_cam[covposition], use_rgb=True)
visualization4=transforms.ToPILImage()(visualization4)
visualization4 = np.array(visualization4)
visualization4=visualize_score(visualization4,score,'confidence increase:')
visualization4=transforms.ToPILImage()(visualization4)

print("reached HHHHHHHERe")
sobel_cam_rgb = cv2.merge([sobel_cam_grayscale[covposition], sobel_cam_grayscale[covposition], sobel_cam_grayscale[covposition]])
x=np.hstack((transforms.ToPILImage()(inputs[0]),sobel_cam_rgb, visualization,visualization1,visualization2,visualization3,visualization4))
visualization=transforms.ToPILImage()(x)
display(visualization)
visualization.save(path+'Sobel_Comparison_correct.png')


